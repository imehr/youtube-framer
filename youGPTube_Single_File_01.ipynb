{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imehr/youtube-framer/blob/main/youGPTube_Single_File_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounting Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the file containing the API key\n",
        "file_path = '/content/drive/MyDrive/For Google Colab/mohem.txt'\n",
        "\n",
        "# Error handling for file reading\n",
        "try:\n",
        "    with open(file_path, 'r') as f:\n",
        "        api_key = f.read().strip()\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found at {file_path}\")\n",
        "    # Exit or handle error accordingly\n",
        "    raise\n",
        "\n",
        "# Check and set API key\n",
        "if api_key:\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "else:\n",
        "    print(\"API key is empty or invalid\")\n",
        "    # Exit or handle error accordingly\n",
        "    raise ValueError(\"Invalid API key\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYj8aHMQLKFQ",
        "outputId": "5933feb0-6845-4bae-9305-e07aaa8694de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_path)  # to confirm the path is correct\n",
        "print(api_key[:5])  # print the first 5 characters of your API key to ensure it's being read correctly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAi5QOPErS0_",
        "outputId": "ec773407-22cb-4496-f10c-7dc2fce4bcc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/For Google Colab/mohem.txt\n",
            "sk-rt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fN99EJ2JA3x"
      },
      "source": [
        "# YouGPTube ü¶æ\n",
        "\n",
        "## TL;DR üëá\n",
        "\n",
        "* Summarize any YouTube video using whisper and chatGPT\n",
        "\n",
        "## How it works ü§î\n",
        "\n",
        "![yougptube](https://user-images.githubusercontent.com/18450628/229377710-95fb8645-3d71-47d0-b3ba-0fd05941b083.png)\n",
        "\n",
        "Here are the main steps:\n",
        "\n",
        "1) Extract the audio using youtube-dl\n",
        "2) Process the audio into smaller chunks\n",
        "3) Each chunk is transcribed using whisper, OpenAI's powerful speech2text model\n",
        "4) Each transcription is summarized using ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JfQu1kQJA3z"
      },
      "source": [
        "## Imports and dependenciesÔ∏è ‚öôÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jq6OlRneJA3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1fb5f7-67ee-47e4-bc2e-aae8a0f1b36f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.9.24-py2.py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt-dlp)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.7.22)\n",
            "Collecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.19.0 websockets-11.0.3 yt-dlp-2023.9.24\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install -U yt-dlp\n",
        "\n",
        "import yt_dlp\n",
        "import os\n",
        "import shutil\n",
        "import librosa\n",
        "import openai\n",
        "import soundfile as sf\n",
        "#from youtube_dl.utils import DownloadError\n",
        "\n",
        "# Assuming the API key is set as an environment variable outside the script\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "assert api_key is not None, \"Set your OpenAI API key\"\n",
        "\n",
        "# Alternatively, read the API key from a file (more secure than hardcoding)\n",
        "# Ensure the file is located in a secure and restricted directory\n",
        "api_key_file_path = '/content/drive/MyDrive/For Google Colab/mohem.txt'  # Replace with your actual path\n",
        "\n",
        "try:\n",
        "    with open(api_key_file_path, 'r') as f:\n",
        "        api_key = f.read().strip()\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "except FileNotFoundError:\n",
        "    print(f\"API key file not found at {api_key_file_path}\")\n",
        "    # Handle error or exit\n",
        "    raise\n",
        "\n",
        "# The rest of your code...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6wJRI0JJA30"
      },
      "source": [
        "## Utility functions üîã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V7brgy5wJA30"
      },
      "outputs": [],
      "source": [
        "def find_audio_files(path, extension=\".mp3\"):\n",
        "    \"\"\"Recursively find all files with extension in path.\"\"\"\n",
        "    audio_files = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if f.endswith(extension):\n",
        "                audio_files.append(os.path.join(root, f))\n",
        "\n",
        "    return audio_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxn7qJsgJA30"
      },
      "source": [
        "## Download youtube audio üîà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GitHJqcJJA30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1bca7e-f3d8-4bab-d823-1743e3b5b917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2023.9.24)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.19.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (11.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.7.22)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U yt-dlp  # Installing yt-dlp\n",
        "\n",
        "from yt_dlp import YoutubeDL\n",
        "import os\n",
        "\n",
        "def youtube_to_mp3(youtube_url: str, output_dir: str) -> (str, str):\n",
        "    \"\"\"Download the audio from a youtube video, save it to output_dir as an .mp3 file.\"\"\"\n",
        "    audio_filename = None\n",
        "    video_title = None\n",
        "\n",
        "    # config\n",
        "    ydl_config = {\n",
        "        \"format\": \"bestaudio/best\",\n",
        "        \"postprocessors\": [{\n",
        "            \"key\": \"FFmpegExtractAudio\",\n",
        "            \"preferredcodec\": \"mp3\",\n",
        "            \"preferredquality\": \"192\",\n",
        "        }],\n",
        "        \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    try:\n",
        "        with YoutubeDL(ydl_config) as ydl:\n",
        "            info_dict = ydl.extract_info(youtube_url, download=False)\n",
        "            video_title = info_dict.get('title', 'Unknown Title')\n",
        "            ydl.download([youtube_url])\n",
        "            audio_filename = find_audio_files(output_dir)[0]  # Assuming `find_audio_files` is defined elsewhere\n",
        "    except Exception as e:  # Catch all exceptions, as yt_dlp may throw various types\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return audio_filename, video_title\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr-6m-HtJA31"
      },
      "source": [
        "## Chunk the audio üç™\n",
        "\n",
        "Chunking is necessary in the case where we have very long audio files, since both whisper and ChatGPT have limits of how much audio/text you can process in one go.\n",
        "It is not necessary for shorter videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eI7KNhjtJA31"
      },
      "outputs": [],
      "source": [
        "def chunk_audio(filename, segment_length: int, output_dir):\n",
        "    \"\"\"segment lenght is in seconds\"\"\"\n",
        "\n",
        "    print(f\"Chunking audio to {segment_length} second segments...\")\n",
        "\n",
        "    if not os.path.isdir(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # load audio file\n",
        "    audio, sr = librosa.load(filename, sr=44100)\n",
        "\n",
        "    # calculate duration in seconds\n",
        "    duration = librosa.get_duration(y=audio, sr=sr)\n",
        "\n",
        "    # calculate number of segments\n",
        "    num_segments = int(duration / segment_length) + 1\n",
        "\n",
        "    print(f\"Chunking {num_segments} chunks...\")\n",
        "\n",
        "    # iterate through segments and save them\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_length * sr\n",
        "        end = (i + 1) * segment_length * sr\n",
        "        segment = audio[start:end]\n",
        "        sf.write(os.path.join(output_dir, f\"segment_{i}.mp3\"), segment, sr)\n",
        "\n",
        "    chunked_audio_files = find_audio_files(output_dir)\n",
        "    return sorted(chunked_audio_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa6C0E7sJA31"
      },
      "source": [
        "## Speech2text üó£\n",
        "\n",
        "Here we use OpenAI's whisper model to transcribe audio files to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d9WDciYAJA31"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(audio_files: list, output_file=None, model=\"whisper-1\") -> list:\n",
        "\n",
        "    print(\"converting audio to text...\")\n",
        "\n",
        "    transcripts = []\n",
        "    for audio_file in audio_files:\n",
        "        audio = open(audio_file, \"rb\")\n",
        "        response = openai.Audio.transcribe(model, audio)\n",
        "        transcripts.append(response[\"text\"])\n",
        "\n",
        "    if output_file is not None:\n",
        "        # save all transcripts to a .txt file\n",
        "        with open(output_file, \"w\") as file:\n",
        "            for transcript in transcripts:\n",
        "                file.write(transcript + \"\\n\")\n",
        "\n",
        "    return transcripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRHnMNTzJA31"
      },
      "source": [
        "## Summarize üìù\n",
        "\n",
        "Here we ask chatGPT to take the raw transcripts and transcribe them for us to short bullet points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zExTxmDrJA32"
      },
      "outputs": [],
      "source": [
        "def summarize(\n",
        "    chunks: list[str], system_prompt: str, model=\"gpt-3.5-turbo\", output_file=None\n",
        "):\n",
        "\n",
        "    print(f\"Summarizing with {model=}\")\n",
        "\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": chunk},\n",
        "            ],\n",
        "        )\n",
        "        summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        summaries.append(summary)\n",
        "\n",
        "    if output_file is not None:\n",
        "        # save all transcripts to a .txt file\n",
        "        with open(output_file, \"w\") as file:\n",
        "            for summary in summaries:\n",
        "                file.write(summary + \"\\n\")\n",
        "\n",
        "    return summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeGf5-2FJA32"
      },
      "source": [
        "## Putting it all together üç±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qrR_4ptqJA32"
      },
      "outputs": [],
      "source": [
        "def summarize_youtube_video(youtube_url, outputs_dir):\n",
        "    raw_audio_dir = f\"{outputs_dir}/raw_audio/\"\n",
        "    chunks_dir = f\"{outputs_dir}/chunks\"\n",
        "    transcripts_file = f\"{outputs_dir}/transcripts.txt\"\n",
        "    summary_file = f\"{outputs_dir}/summary.txt\"\n",
        "    segment_length = 10 * 60  # chunk to 10 minute segments\n",
        "\n",
        "    if os.path.exists(outputs_dir):\n",
        "        # delete the outputs_dir folder and start from scratch\n",
        "        shutil.rmtree(outputs_dir)\n",
        "        os.mkdir(outputs_dir)\n",
        "\n",
        "    # download the video using youtube-dl\n",
        "    audio_filename, video_title = youtube_to_mp3(youtube_url, output_dir=raw_audio_dir)\n",
        "\n",
        "\n",
        "    # chunk each audio file to shorter audio files (not necessary for shorter videos...)\n",
        "    chunked_audio_files = chunk_audio(\n",
        "        audio_filename, segment_length=segment_length, output_dir=chunks_dir\n",
        "    )\n",
        "\n",
        "    # transcribe each chunked audio file using whisper speech2text\n",
        "    transcriptions = transcribe_audio(chunked_audio_files, transcripts_file)\n",
        "\n",
        "    # summarize each transcription using chatGPT\n",
        "    system_prompt = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    You are provided chunks of raw audio that were transcribed from the video's audio.\n",
        "    Summarize the current chunk to succint and clear bullet points of its contents.\n",
        "    \"\"\"\n",
        "    summaries = summarize(\n",
        "        transcriptions, system_prompt=system_prompt, output_file=summary_file\n",
        "    )\n",
        "\n",
        "    system_prompt_tldr = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    Someone has already summarized the video to key points.\n",
        "    Summarize the key points to one or two sentences that capture the essence of the video.\n",
        "    \"\"\"\n",
        "    # put the entire summary to a single entry\n",
        "    long_summary = \"\\n\".join(summaries)\n",
        "    short_summary = summarize(\n",
        "        [long_summary], system_prompt=system_prompt_tldr, output_file=summary_file\n",
        "    )[0]\n",
        "\n",
        "    return long_summary, short_summary, video_title"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to summarize a single video\n",
        "def summarize_single_video(youtube_url, outputs_dir):\n",
        "    audio_filename, video_title = youtube_to_mp3(youtube_url, output_dir=outputs_dir)\n",
        "    long_summary, short_summary = summarize_youtube_video(audio_filename, outputs_dir)  # Assuming summarize_youtube_video is defined elsewhere\n",
        "    save_to_markdown_file(video_title, youtube_url, long_summary, short_summary, outputs_dir)"
      ],
      "metadata": {
        "id": "8QiURyuw2i7N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFRJ1CuSJA32"
      },
      "outputs": [],
      "source": [
        "# Your existing imports and configurations\n",
        "import openai\n",
        "\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Function to save markdown\n",
        "def save_to_markdown_file(video_title, youtube_url, long_summary, short_summary, output_dir):\n",
        "    # Sanitize the video title to create a valid filename\n",
        "    sanitized_title = ''.join(e for e in video_title if e.isalnum() or e == ' ').replace(' ', '_')\n",
        "    markdown_filename = f\"{output_dir}/{sanitized_title}.md\"\n",
        "\n",
        "    # Create or overwrite the markdown file\n",
        "    with open(markdown_filename, 'w') as f:\n",
        "        f.write(f\"# {video_title}\\n\\n\")\n",
        "        f.write(f\"## YouTube URL\\n{youtube_url}\\n\\n\")\n",
        "        f.write(\"## Long Summary\\n\")\n",
        "        f.write(long_summary)\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write(\"## TL;DR\\n\")\n",
        "        f.write(short_summary)\n",
        "\n",
        "# Your code to generate summaries\n",
        "youtube_url = \"https://www.youtube.com/watch?v=KH0XNW0t6-k\"\n",
        "outputs_dir = \"outputs/\"\n",
        "\n",
        "long_summary, short_summary, video_title = summarize_youtube_video(youtube_url, outputs_dir)\n",
        "\n",
        "# Your code to display summaries\n",
        "print(\"Summaries:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Long summary:\")\n",
        "print(\"=\" * 80)\n",
        "print(long_summary)\n",
        "print()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Video - TL;DR\")\n",
        "print(\"=\" * 80)\n",
        "print(short_summary)\n",
        "\n",
        "# Add this line to save the summaries to a markdown file\n",
        "# Replace 'Your Video Title' with the actual video title\n",
        "# video_title = 'Your Video Title'\n",
        "save_to_markdown_file(video_title, youtube_url, long_summary, short_summary, outputs_dir)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "youGPTube",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}